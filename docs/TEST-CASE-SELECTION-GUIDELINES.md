# Test Case Selection Guidelines

## üéØ Philosophy: Quality Over Quantity

**Select test cases judiciously based on feature needs, complexity, and risk rather than meeting arbitrary numerical goals.**

## üìã Test Case Selection Criteria

### **When to Create Test Cases**

#### **‚úÖ Always Test:**
- **Core functionality** - Primary feature behavior
- **Error conditions** - Failure modes and edge cases
- **Integration points** - Interfaces with other components
- **Security boundaries** - Authentication, authorization, data validation
- **Performance critical paths** - Bottlenecks and resource-intensive operations

#### **‚úÖ Consider Testing:**
- **Complex business logic** - Multi-step workflows
- **Data transformations** - Input/output processing
- **Configuration variations** - Different setup scenarios
- **User interaction flows** - Critical user journeys

#### **‚ùå Avoid Over-Testing:**
- **Simple getters/setters** - Trivial property access
- **Framework functionality** - Well-tested third-party code
- **Obvious implementations** - Straightforward logic
- **Duplicate scenarios** - Already covered by other tests

### **When to Create Sub-Test Cases**

#### **‚úÖ Use Sub-Tests For:**
- **Parameterized testing** - Same logic, different input values
- **Boundary value testing** - Min/max/edge values
- **Data-driven scenarios** - Multiple datasets for same test
- **Cross-platform variations** - Same test across environments

#### **‚ùå Don't Use Sub-Tests For:**
- **Different logic paths** - Create separate test cases instead
- **Unrelated scenarios** - Group logically related tests only
- **Complex setup variations** - Use separate test cases for clarity

## üéØ Feature-Based Test Selection

### **Simple Features (1-2 Test Cases)**
- **Basic CRUD operations** - Create, read, update, delete
- **Simple validations** - Input format checking
- **Configuration loading** - File parsing and validation

**Example:**
```
## FT-CONFIG-001 - Configuration Loading
- **TC-CONFIG-001** - Valid Configuration (Automated, High)
- **TC-CONFIG-002** - Invalid Configuration Handling (Automated, Medium)
```

### **Moderate Features (2-4 Test Cases)**
- **API endpoints** - Request/response handling
- **Data processing** - Transformation and validation
- **User authentication** - Login/logout flows

**Example:**
```
## FT-AUTH-001 - User Authentication
- **TC-AUTH-001** - Successful Login (Automated, High)
- **TC-AUTH-002** - Invalid Credentials (Automated, High)
- **TC-AUTH-003** - Session Management (Automated, Medium)
```

### **Complex Features (3-6 Test Cases)**
- **Multi-step workflows** - Complex business processes
- **Integration systems** - External service interactions
- **Advanced algorithms** - Complex computational logic

**Example:**
```
## FT-WORKFLOW-001 - Document Processing Pipeline
- **TC-WORKFLOW-001** - Complete Processing (Automated, High)
- **TC-WORKFLOW-002** - Partial Failure Recovery (Automated, High)
- **TC-WORKFLOW-003** - Format Validation (Automated, Medium)
- **TC-WORKFLOW-004** - Performance Thresholds (Automated, Medium)
```

## üîç Sub-Test Case Examples

### **‚úÖ Good Sub-Test Usage:**
```
- **TC-VALIDATION-001** - Input Format Validation (Automated, High)
    - **TC-VALIDATION-001a** - Email Format - Test valid email formats
    - **TC-VALIDATION-001b** - Phone Format - Test valid phone formats  
    - **TC-VALIDATION-001c** - Date Format - Test valid date formats
```

### **‚ùå Poor Sub-Test Usage:**
```
- **TC-USER-001** - User Management (Automated, High)
    - **TC-USER-001a** - Create User - Test user creation
    - **TC-USER-001b** - Delete User - Test user deletion
    - **TC-USER-001c** - Send Email - Test email notifications
```
*These should be separate test cases as they test different functionality.*

## üìä Decision Framework

### **Test Case Decision Tree:**

1. **Is this core functionality?** ‚Üí Yes: Create test case
2. **Does failure impact users significantly?** ‚Üí Yes: Create test case  
3. **Is this complex or error-prone logic?** ‚Üí Yes: Create test case
4. **Is this already covered by other tests?** ‚Üí Yes: Skip test case
5. **Is this trivial or framework code?** ‚Üí Yes: Skip test case

### **Sub-Test Decision Tree:**

1. **Same test logic with different inputs?** ‚Üí Yes: Use sub-tests
2. **Testing boundary conditions?** ‚Üí Yes: Use sub-tests
3. **Different logic or setup required?** ‚Üí No: Use separate test cases
4. **Unrelated functionality?** ‚Üí No: Use separate test cases

## üéØ Quality Indicators

### **Good Test Coverage:**
- **Focused on risk** - Tests address real failure scenarios
- **Clear purpose** - Each test has specific objective
- **Maintainable** - Tests are easy to understand and update
- **Efficient** - No redundant or overlapping tests

### **Poor Test Coverage:**
- **Arbitrary numbers** - "Must have 5 test cases per feature"
- **Trivial tests** - Testing obvious or framework functionality
- **Redundant tests** - Multiple tests covering same scenario
- **Complex sub-tests** - Sub-tests that should be separate cases

## üìã Implementation Guidelines

### **For Feature Documentation:**
1. **Analyze feature complexity** and risk profile
2. **Identify critical paths** and failure modes
3. **Select minimum viable test coverage** for confidence
4. **Group related scenarios** logically
5. **Use sub-tests sparingly** and appropriately

### **For Test Implementation:**
1. **Start with core functionality** tests
2. **Add error condition** tests
3. **Include integration** tests if applicable
4. **Consider performance** tests for critical paths
5. **Review for redundancy** and consolidate

## üéØ Examples by Feature Type

### **Documentation Features (1-2 Test Cases):**
```
## FT-DOC-001 - Template System
- **TC-DOC-001** - Template Processing (Manual, Medium)
- **TC-DOC-002** - Placeholder Replacement (Manual, Low)
```

### **Configuration Features (2-3 Test Cases):**
```
## FT-CONFIG-001 - Project Configuration
- **TC-CONFIG-001** - Valid Configuration (Automated, High)
- **TC-CONFIG-002** - Migration Handling (Automated, Medium)
- **TC-CONFIG-003** - Validation Errors (Automated, Medium)
```

### **Processing Features (3-5 Test Cases):**
```
## FT-SCAN-001 - Code Analysis
- **TC-SCAN-001** - File Discovery (Automated, High)
- **TC-SCAN-002** - Language Detection (Automated, High)
    - **TC-SCAN-002a** - Python Files - Test .py file detection
    - **TC-SCAN-002b** - JavaScript Files - Test .js/.ts file detection
- **TC-SCAN-003** - Test Case Extraction (Automated, High)
- **TC-SCAN-004** - Error Handling (Automated, Medium)
```

---

**Remember: The goal is confident coverage of feature functionality, not meeting test count quotas. Focus on what matters for feature reliability and user experience.**
