metadata:
  name: Testing Pass
  number: 5
  purpose: Adding comprehensive test coverage and verifying edge cases, focusing on the test cases documented in `TEST-CASES.md`.
  role: Assume the role of a **Senior QA Engineer** with expertise in test strategy, automation, and quality assurance. Apply rigorous testing methodologies, focus on edge cases, and ensure comprehensive coverage. Think like a quality-focused professional who takes pride in finding issues before they reach production.
  description: Converted from 5_testing_pass.md
when_to_use:
  conditions:
  - After an Implementation Pass has established basic functionality
  - When increasing test coverage for existing features
  - Before releasing features to production
  - When addressing quality concerns or bug reports
  - As part of regular quality assurance cycles
  prerequisites: []
process:
  workflow_pattern: "SCAN → DRAFT → ASK → SYNC → CONFIRM"
  phases:
    'scan:':
      description: Review coverage gaps, analyze `TEST-CASES.md`, identify edge cases, check bug reports
      actions: []
    'draft:':
      description: Plan test strategy, document edge cases, identify integration scenarios, plan performance tests
      actions: []
    'ask:':
      description: Clarify edge case behavior, confirm priorities, verify acceptance criteria
      actions: []
    'sync:':
      description: "Implement test suite, add edge case tests, create integration tests, update `TEST-CASES.md`


        **Note:** During execution, mark completed steps with ✅ to track progress."
      actions: []
expected_outcomes:
- Comprehensive test coverage
- Edge case and error tests
- Integration tests
- Updated test documentation
- Increased quality confidence

# Testing Framework Classification
testing_framework_rules:
  critical_distinction: "Test implementation depends on Code Location framework type"

  automated_testing_scope:
    description: "ONLY create automated tests for Code Framework features"
    applicable_to:
    - "Features with Code Location pointing to .py, .js, .ts, .java, .go files"
    - "Executable code that can be unit/integration tested"
    - "APIs, functions, classes, and modules"
    testing_approach:
    - "Create pytest/jest/junit test files"
    - "Implement unit and integration tests"
    - "Add to CI/CD pipeline"
    - "Achieve target coverage metrics"

  manual_validation_scope:
    description: "NO automated tests for Documentation/Configuration/Process features"
    applicable_to:
    - "Features with Code Location pointing to .md, .yml, .json files"
    - "Documentation framework features (docs/, README, etc.)"
    - "Configuration framework features (.agent3d-config.yml, passes.yml/)"
    - "Process features with N/A or descriptive Code Locations"
    validation_approach:
    - "Manual review and validation only"
    - "Schema validation for configuration files"
    - "Process adherence verification"
    - "Documentation quality assessment"

  implementation_guidelines:
    before_creating_tests:
    - "Check Code Location field of the feature"
    - "Identify framework type (Code/Documentation/Configuration/Process)"
    - "Apply appropriate testing strategy"
    - "Do NOT create automated tests for non-code features"

    test_organization:
    - "Group tests by feature module/component"
    - "Use TC ID comments for drift scanner detection"
    - "Follow language-specific testing conventions"
    - "Maintain test documentation and coverage reports"

quality_gates:
- name: "framework_classification_followed"
  validation: "Tests created only for Code Framework features"
  critical: true
- name: "manual_validation_documented"
  validation: "Manual validation approach documented for non-code features"
  critical: true
- name: "test_coverage_appropriate"
  validation: "Coverage metrics apply only to testable code"
  critical: true
